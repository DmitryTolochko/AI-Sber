{
  "best_global_step": 12000,
  "best_metric": 0.41174812857031756,
  "best_model_checkpoint": "./nanai_lora_reverse/checkpoint-12000",
  "epoch": 10.0,
  "eval_steps": 1000,
  "global_step": 13620,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3671071953010279,
      "grad_norm": 0.9075649976730347,
      "learning_rate": 0.000499,
      "loss": 9.8865,
      "step": 500
    },
    {
      "epoch": 0.7342143906020558,
      "grad_norm": 0.7508087754249573,
      "learning_rate": 0.0004982175127964996,
      "loss": 9.4802,
      "step": 1000
    },
    {
      "epoch": 0.7342143906020558,
      "eval_bleu": 0.03327695381803027,
      "eval_loss": 9.370074272155762,
      "eval_runtime": 520.0662,
      "eval_samples_per_second": 2.327,
      "eval_steps_per_second": 0.292,
      "eval_word_accuracy": 0.04813969619863487,
      "step": 1000
    },
    {
      "epoch": 1.1013215859030836,
      "grad_norm": 0.6774211525917053,
      "learning_rate": 0.0004928812925916675,
      "loss": 9.3637,
      "step": 1500
    },
    {
      "epoch": 1.4684287812041115,
      "grad_norm": 0.5518776774406433,
      "learning_rate": 0.00048406773109889103,
      "loss": 9.2901,
      "step": 2000
    },
    {
      "epoch": 1.4684287812041115,
      "eval_bleu": 0.11245161142655538,
      "eval_loss": 9.250466346740723,
      "eval_runtime": 341.6944,
      "eval_samples_per_second": 3.541,
      "eval_steps_per_second": 0.445,
      "eval_word_accuracy": 0.13754464828442003,
      "step": 2000
    },
    {
      "epoch": 1.8355359765051396,
      "grad_norm": 0.49254733324050903,
      "learning_rate": 0.00047190301243447513,
      "loss": 9.2564,
      "step": 2500
    },
    {
      "epoch": 2.202643171806167,
      "grad_norm": 0.7104284763336182,
      "learning_rate": 0.00045656129936746904,
      "loss": 9.2299,
      "step": 3000
    },
    {
      "epoch": 2.202643171806167,
      "eval_bleu": 0.20152536638040677,
      "eval_loss": 9.181068420410156,
      "eval_runtime": 291.9216,
      "eval_samples_per_second": 4.145,
      "eval_steps_per_second": 0.521,
      "eval_word_accuracy": 0.22399334007712332,
      "step": 3000
    },
    {
      "epoch": 2.5697503671071953,
      "grad_norm": 0.8063727021217346,
      "learning_rate": 0.00043826223982425857,
      "loss": 9.1769,
      "step": 3500
    },
    {
      "epoch": 2.936857562408223,
      "grad_norm": 1.4859856367111206,
      "learning_rate": 0.00041726782218032206,
      "loss": 9.1731,
      "step": 4000
    },
    {
      "epoch": 2.936857562408223,
      "eval_bleu": 0.245949544535293,
      "eval_loss": 9.153282165527344,
      "eval_runtime": 352.5166,
      "eval_samples_per_second": 3.432,
      "eval_steps_per_second": 0.431,
      "eval_word_accuracy": 0.275992837245172,
      "step": 4000
    },
    {
      "epoch": 3.303964757709251,
      "grad_norm": 0.7432419657707214,
      "learning_rate": 0.0003938786243620638,
      "loss": 9.1817,
      "step": 4500
    },
    {
      "epoch": 3.671071953010279,
      "grad_norm": 0.701619565486908,
      "learning_rate": 0.0003684295104604868,
      "loss": 9.1496,
      "step": 5000
    },
    {
      "epoch": 3.671071953010279,
      "eval_bleu": 0.3072534089648097,
      "eval_loss": 9.119590759277344,
      "eval_runtime": 330.9203,
      "eval_samples_per_second": 3.656,
      "eval_steps_per_second": 0.459,
      "eval_word_accuracy": 0.33615217442821516,
      "step": 5000
    },
    {
      "epoch": 4.038179148311307,
      "grad_norm": 0.6102877259254456,
      "learning_rate": 0.00034128483646846,
      "loss": 9.0912,
      "step": 5500
    },
    {
      "epoch": 4.405286343612334,
      "grad_norm": 0.6368919014930725,
      "learning_rate": 0.0003128332337812343,
      "loss": 9.1003,
      "step": 6000
    },
    {
      "epoch": 4.405286343612334,
      "eval_bleu": 0.3250985511560723,
      "eval_loss": 9.101473808288574,
      "eval_runtime": 313.2916,
      "eval_samples_per_second": 3.862,
      "eval_steps_per_second": 0.485,
      "eval_word_accuracy": 0.3585299037857695,
      "step": 6000
    },
    {
      "epoch": 4.772393538913363,
      "grad_norm": 0.596642255783081,
      "learning_rate": 0.0002834820451450413,
      "loss": 9.0766,
      "step": 6500
    },
    {
      "epoch": 5.139500734214391,
      "grad_norm": 0.5246682167053223,
      "learning_rate": 0.00025365149271452166,
      "loss": 9.0738,
      "step": 7000
    },
    {
      "epoch": 5.139500734214391,
      "eval_bleu": 0.3652364140931724,
      "eval_loss": 9.089940071105957,
      "eval_runtime": 266.3768,
      "eval_samples_per_second": 4.542,
      "eval_steps_per_second": 0.571,
      "eval_word_accuracy": 0.39190243345995207,
      "step": 7000
    },
    {
      "epoch": 5.506607929515418,
      "grad_norm": 0.7032819986343384,
      "learning_rate": 0.00022376866171514498,
      "loss": 9.0654,
      "step": 7500
    },
    {
      "epoch": 5.873715124816447,
      "grad_norm": 0.568968653678894,
      "learning_rate": 0.00019426138584676528,
      "loss": 9.0595,
      "step": 8000
    },
    {
      "epoch": 5.873715124816447,
      "eval_bleu": 0.3807345979676778,
      "eval_loss": 9.07990550994873,
      "eval_runtime": 260.4665,
      "eval_samples_per_second": 4.646,
      "eval_steps_per_second": 0.584,
      "eval_word_accuracy": 0.40337005512689317,
      "step": 8000
    },
    {
      "epoch": 6.240822320117474,
      "grad_norm": 0.5106157064437866,
      "learning_rate": 0.00016555212197123876,
      "loss": 9.0466,
      "step": 8500
    },
    {
      "epoch": 6.607929515418502,
      "grad_norm": 0.5183672308921814,
      "learning_rate": 0.00013805190178044913,
      "loss": 9.0396,
      "step": 9000
    },
    {
      "epoch": 6.607929515418502,
      "eval_bleu": 0.38994536028801396,
      "eval_loss": 9.074675559997559,
      "eval_runtime": 264.4655,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 0.575,
      "eval_word_accuracy": 0.41552337701162,
      "step": 9000
    },
    {
      "epoch": 6.975036710719531,
      "grad_norm": 0.5916354656219482,
      "learning_rate": 0.00011215444703895305,
      "loss": 9.0445,
      "step": 9500
    },
    {
      "epoch": 7.342143906020558,
      "grad_norm": 0.8921003341674805,
      "learning_rate": 8.823053265355527e-05,
      "loss": 9.0235,
      "step": 10000
    },
    {
      "epoch": 7.342143906020558,
      "eval_bleu": 0.39537850412875847,
      "eval_loss": 9.070433616638184,
      "eval_runtime": 272.8499,
      "eval_samples_per_second": 4.435,
      "eval_steps_per_second": 0.557,
      "eval_word_accuracy": 0.42360763121375156,
      "step": 10000
    },
    {
      "epoch": 7.709251101321586,
      "grad_norm": 0.5683157444000244,
      "learning_rate": 6.662267827397384e-05,
      "loss": 9.0351,
      "step": 10500
    },
    {
      "epoch": 8.076358296622614,
      "grad_norm": 0.6676886081695557,
      "learning_rate": 4.764024442516429e-05,
      "loss": 9.0129,
      "step": 11000
    },
    {
      "epoch": 8.076358296622614,
      "eval_bleu": 0.4076452145887586,
      "eval_loss": 9.06847858428955,
      "eval_runtime": 276.4549,
      "eval_samples_per_second": 4.377,
      "eval_steps_per_second": 0.55,
      "eval_word_accuracy": 0.4321945432753841,
      "step": 11000
    },
    {
      "epoch": 8.443465491923641,
      "grad_norm": 0.5487287640571594,
      "learning_rate": 3.155500338017303e-05,
      "loss": 9.0316,
      "step": 11500
    },
    {
      "epoch": 8.810572687224669,
      "grad_norm": 0.759594202041626,
      "learning_rate": 1.8597248185514615e-05,
      "loss": 9.0067,
      "step": 12000
    },
    {
      "epoch": 8.810572687224669,
      "eval_bleu": 0.41174812857031756,
      "eval_loss": 9.066906929016113,
      "eval_runtime": 274.0769,
      "eval_samples_per_second": 4.415,
      "eval_steps_per_second": 0.555,
      "eval_word_accuracy": 0.43581976872243733,
      "step": 12000
    },
    {
      "epoch": 9.177679882525698,
      "grad_norm": 0.5138832330703735,
      "learning_rate": 8.952495546311363e-06,
      "loss": 9.0416,
      "step": 12500
    },
    {
      "epoch": 9.544787077826726,
      "grad_norm": 0.5922726988792419,
      "learning_rate": 2.7588297761241e-06,
      "loss": 9.007,
      "step": 13000
    },
    {
      "epoch": 9.544787077826726,
      "eval_bleu": 0.41104156403109726,
      "eval_loss": 9.066703796386719,
      "eval_runtime": 260.8831,
      "eval_samples_per_second": 4.638,
      "eval_steps_per_second": 0.583,
      "eval_word_accuracy": 0.43466562901457867,
      "step": 13000
    },
    {
      "epoch": 9.911894273127754,
      "grad_norm": 0.5804204940795898,
      "learning_rate": 1.0492583825116863e-07,
      "loss": 9.0108,
      "step": 13500
    }
  ],
  "logging_steps": 500,
  "max_steps": 13620,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.959599609053184e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
